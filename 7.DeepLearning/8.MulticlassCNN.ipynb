{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 16:39:49.058782: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError #PIL is python image library\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from a directory and label them\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted([d for d in os.listdir(folder) if os.path.isdir(os.path.join(folder, d))])  # Filter to only directories\n",
    "    for label, class_name in enumerate(class_names):\n",
    "        class_folder = os.path.join(folder, class_name)\n",
    "        for filename in os.listdir(class_folder):\n",
    "            img_path = os.path.join(class_folder, filename)\n",
    "            try:\n",
    "                # Open the image file and convert to RGB\n",
    "                with Image.open(img_path) as img:\n",
    "                    img = img.convert('RGB')  # Ensure all images are RGB\n",
    "                    img = img.resize((100, 100))\n",
    "                    img_array = np.array(img)\n",
    "                    images.append(img_array)\n",
    "                    labels.append(label)\n",
    "            except (IOError, UnidentifiedImageError) as e:\n",
    "                # Skip files that can't be identified as images\n",
    "                print(f\"Skipping file {img_path}: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load training and testing data\n",
    "train_folder = 'multiclassCNN/train'\n",
    "test_folder = 'multiclassCNN/test'\n",
    "\n",
    "x_train, y_train = load_images_from_folder(train_folder)\n",
    "x_test, y_test = load_images_from_folder(test_folder)\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax') \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define callbacks\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "#lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 339ms/step - accuracy: 0.1098 - loss: 2.6880 - val_accuracy: 0.2097 - val_loss: 2.4901\n",
      "Epoch 2/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 304ms/step - accuracy: 0.1981 - loss: 2.4806 - val_accuracy: 0.2629 - val_loss: 2.3298\n",
      "Epoch 3/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 349ms/step - accuracy: 0.2584 - loss: 2.3074 - val_accuracy: 0.2971 - val_loss: 2.2072\n",
      "Epoch 4/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 346ms/step - accuracy: 0.2915 - loss: 2.2001 - val_accuracy: 0.3259 - val_loss: 2.1160\n",
      "Epoch 5/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 354ms/step - accuracy: 0.3229 - loss: 2.1787 - val_accuracy: 0.3444 - val_loss: 2.0748\n",
      "Epoch 6/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 351ms/step - accuracy: 0.3364 - loss: 2.1146 - val_accuracy: 0.3770 - val_loss: 2.0192\n",
      "Epoch 7/10\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 376ms/step - accuracy: 0.3630 - loss: 2.0641 - val_accuracy: 0.3639 - val_loss: 1.9735\n",
      "Epoch 8/10\n",
      "\u001b[1m 36/229\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 338ms/step - accuracy: 0.3322 - loss: 2.1066"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=10, validation_data=(x_test, y_test))  # , callbacks=[early_stopping, lr_scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a random image and its prediction\n",
    "idx2 = random.randint(0, len(x_test) - 1)\n",
    "plt.imshow(x_test[idx2])\n",
    "plt.show()\n",
    "\n",
    "# Predict the class of the image\n",
    "y_pred = model.predict(x_test[idx2, :].reshape(1, 100, 100, 3))\n",
    "predicted_class_idx = np.argmax(y_pred)\n",
    "\n",
    "# Get the class names from the folder structure\n",
    "class_names = sorted([d for d in os.listdir(train_folder) if os.path.isdir(os.path.join(train_folder, d))])\n",
    "\n",
    "# Map the predicted class index and actual class index to their respective class names\n",
    "predicted_class_name = class_names[predicted_class_idx]\n",
    "actual_class_name = class_names[np.argmax(y_test[idx2])]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class_name}, Actual Class: {actual_class_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
